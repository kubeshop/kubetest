"use strict";(self.webpackChunktestkube_documentation=self.webpackChunktestkube_documentation||[]).push([[3933],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>m});var n=a(67294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var o=n.createContext({}),p=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=p(e.components);return n.createElement(o.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,r=e.originalType,o=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(a),m=l,h=c["".concat(o,".").concat(m)]||c[m]||d[m]||r;return a?n.createElement(h,i(i({ref:t},u),{},{components:a})):n.createElement(h,i({ref:t},u))}));function m(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var r=a.length,i=new Array(r);i[0]=c;var s={};for(var o in t)hasOwnProperty.call(t,o)&&(s[o]=t[o]);s.originalType=e,s.mdxType="string"==typeof e?e:l,i[1]=s;for(var p=2;p<r;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},85162:(e,t,a)=>{a.d(t,{Z:()=>i});var n=a(67294),l=a(86010);const r="tabItem_Ymn6";function i(e){let{children:t,hidden:a,className:i}=e;return n.createElement("div",{role:"tabpanel",className:(0,l.Z)(r,i),hidden:a},t)}},74866:(e,t,a)=>{a.d(t,{Z:()=>v});var n=a(87462),l=a(67294),r=a(86010),i=a(12466),s=a(76775),o=a(91980),p=a(67392),u=a(50012);function d(e){return function(e){var t;return(null==(t=l.Children.map(e,(e=>{if(!e||(0,l.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})))?void 0:t.filter(Boolean))??[]}(e).map((e=>{let{props:{value:t,label:a,attributes:n,default:l}}=e;return{value:t,label:a,attributes:n,default:l}}))}function c(e){const{values:t,children:a}=e;return(0,l.useMemo)((()=>{const e=t??d(a);return function(e){const t=(0,p.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,a])}function m(e){let{value:t,tabValues:a}=e;return a.some((e=>e.value===t))}function h(e){let{queryString:t=!1,groupId:a}=e;const n=(0,s.k6)(),r=function(e){let{queryString:t=!1,groupId:a}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!a)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return a??null}({queryString:t,groupId:a});return[(0,o._X)(r),(0,l.useCallback)((e=>{if(!r)return;const t=new URLSearchParams(n.location.search);t.set(r,e),n.replace({...n.location,search:t.toString()})}),[r,n])]}function k(e){const{defaultValue:t,queryString:a=!1,groupId:n}=e,r=c(e),[i,s]=(0,l.useState)((()=>function(e){let{defaultValue:t,tabValues:a}=e;if(0===a.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:a}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${a.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const n=a.find((e=>e.default))??a[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:t,tabValues:r}))),[o,p]=h({queryString:a,groupId:n}),[d,k]=function(e){let{groupId:t}=e;const a=function(e){return e?`docusaurus.tab.${e}`:null}(t),[n,r]=(0,u.Nk)(a);return[n,(0,l.useCallback)((e=>{a&&r.set(e)}),[a,r])]}({groupId:n}),f=(()=>{const e=o??d;return m({value:e,tabValues:r})?e:null})();(0,l.useLayoutEffect)((()=>{f&&s(f)}),[f]);return{selectedValue:i,selectValue:(0,l.useCallback)((e=>{if(!m({value:e,tabValues:r}))throw new Error(`Can't select invalid tab value=${e}`);s(e),p(e),k(e)}),[p,k,r]),tabValues:r}}var f=a(72389);const g="tabList__CuJ",y="tabItem_LNqP";function w(e){let{className:t,block:a,selectedValue:s,selectValue:o,tabValues:p}=e;const u=[],{blockElementScrollPositionUntilNextRender:d}=(0,i.o5)(),c=e=>{const t=e.currentTarget,a=u.indexOf(t),n=p[a].value;n!==s&&(d(t),o(n))},m=e=>{var t;let a=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=u.indexOf(e.currentTarget)+1;a=u[t]??u[0];break}case"ArrowLeft":{const t=u.indexOf(e.currentTarget)-1;a=u[t]??u[u.length-1];break}}null==(t=a)||t.focus()};return l.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.Z)("tabs",{"tabs--block":a},t)},p.map((e=>{let{value:t,label:a,attributes:i}=e;return l.createElement("li",(0,n.Z)({role:"tab",tabIndex:s===t?0:-1,"aria-selected":s===t,key:t,ref:e=>u.push(e),onKeyDown:m,onClick:c},i,{className:(0,r.Z)("tabs__item",y,null==i?void 0:i.className,{"tabs__item--active":s===t})}),a??t)})))}function b(e){let{lazy:t,children:a,selectedValue:n}=e;const r=(Array.isArray(a)?a:[a]).filter(Boolean);if(t){const e=r.find((e=>e.props.value===n));return e?(0,l.cloneElement)(e,{className:"margin-top--md"}):null}return l.createElement("div",{className:"margin-top--md"},r.map(((e,t)=>(0,l.cloneElement)(e,{key:t,hidden:e.props.value!==n}))))}function N(e){const t=k(e);return l.createElement("div",{className:(0,r.Z)("tabs-container",g)},l.createElement(w,(0,n.Z)({},e,t)),l.createElement(b,(0,n.Z)({},e,t)))}function v(e){const t=(0,f.Z)();return l.createElement(N,(0,n.Z)({key:String(t)},e))}},28782:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>p,toc:()=>d});var n=a(87462),l=(a(67294),a(3905)),r=a(74866),i=a(85162);const s={},o="Test Workflows - Parallel Steps",p={unversionedId:"articles/test-workflows-parallel",id:"articles/test-workflows-parallel",title:"Test Workflows - Parallel Steps",description:"Often you would like to speed up the test execution, by distributing the load across multiple runs.",source:"@site/docs/articles/test-workflows-parallel.md",sourceDirName:"articles",slug:"/articles/test-workflows-parallel",permalink:"/articles/test-workflows-parallel",draft:!1,editUrl:"https://github.com/kubeshop/testkube/tree/develop/docs/docs/articles/test-workflows-parallel.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Test Workflows - Test Suites",permalink:"/articles/test-workflows-test-suites"},next:{title:"Test Workflows - Services",permalink:"/articles/test-workflows-services"}},u={},d=[{value:"Syntax",id:"syntax",level:2},{value:"Basic configuration",id:"basic-configuration",level:3},{value:"Fetching logs",id:"fetching-logs",level:3},{value:"Pod and Job configuration",id:"pod-and-job-configuration",level:3},{value:"Lifecycle",id:"lifecycle",level:3},{value:"Matrix and sharding",id:"matrix-and-sharding",level:3},{value:"Providing content",id:"providing-content",level:2},{value:"Copying content inside",id:"copying-content-inside",level:3},{value:"Example",id:"example",level:4},{value:"Static content or a Git repository",id:"static-content-or-a-git-repository",level:3},{value:"Synchronising the parallel steps execution",id:"synchronising-the-parallel-steps-execution",level:2},{value:"Reading files from parallel steps",id:"reading-files-from-parallel-steps",level:2},{value:"Artifacts",id:"artifacts",level:3},{value:"Fetching files back to execution&#39;s Pod",id:"fetching-files-back-to-executions-pod",level:3},{value:"Examples",id:"examples",level:2},{value:"Sharded Playwright with single report",id:"sharded-playwright-with-single-report",level:3},{value:"Automatically sharded Cypress tests",id:"automatically-sharded-cypress-tests",level:3},{value:"Distributed K6 load testing",id:"distributed-k6-load-testing",level:3}],c={toc:d};function m(e){let{components:t,...s}=e;return(0,l.kt)("wrapper",(0,n.Z)({},c,s,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"test-workflows---parallel-steps"},"Test Workflows - Parallel Steps"),(0,l.kt)("p",null,"Often you would like to speed up the test execution, by distributing the load across multiple runs."),(0,l.kt)("p",null,"Test Workflows have ",(0,l.kt)("inlineCode",{parentName:"p"},"parallel")," steps, that allow you to distribute your test even dynamically, and among multiple cluster nodes."),(0,l.kt)("h2",{id:"syntax"},"Syntax"),(0,l.kt)("p",null,"To declare the parallel step, you need to specify the step with ",(0,l.kt)("inlineCode",{parentName:"p"},"parallel")," clause."),(0,l.kt)("h3",{id:"basic-configuration"},"Basic configuration"),(0,l.kt)("p",null,"It allows to provide:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"similar properties as any other kind of step, i.e. ",(0,l.kt)("inlineCode",{parentName:"li"},"container"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"run"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"shell")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"steps")),(0,l.kt)("li",{parentName:"ul"},"general Test Workflow properties, like ",(0,l.kt)("inlineCode",{parentName:"li"},"job"),", ",(0,l.kt)("inlineCode",{parentName:"li"},"pod")," or ",(0,l.kt)("inlineCode",{parentName:"li"},"content")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"/articles/test-workflows-matrix-and-sharding"},(0,l.kt)("strong",{parentName:"a"},"matrix and sharding"))," properties"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"parallelism")," to define maximum number of instances to run at once"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"description")," that may provide human-readable information for each instance separately")),(0,l.kt)("h3",{id:"fetching-logs"},"Fetching logs"),(0,l.kt)("p",null,"By default the logs for the parallel steps are saved. To disable them or make them conditional, you can use ",(0,l.kt)("inlineCode",{parentName:"p"},"logs")," property.\nIt takes an expression condition, so you can dynamically choose whether it should be saved or not. Often you will use:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"logs: never")," to never store the logs"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"logs: failed")," to store logs only if the step has failed")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-parallel-log.png",src:a(87742).Z,width:"2160",height:"2092"})),(0,l.kt)("h3",{id:"pod-and-job-configuration"},"Pod and Job configuration"),(0,l.kt)("p",null,"The parallel steps are started as a separate jobs/pods, so you can configure ",(0,l.kt)("inlineCode",{parentName:"p"},"pod")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"job")," similarly to general Test Workflow."),(0,l.kt)("h3",{id:"lifecycle"},"Lifecycle"),(0,l.kt)("p",null,"Similarly to regular steps, you can configure things like ",(0,l.kt)("inlineCode",{parentName:"p"},"timeout")," (",(0,l.kt)("inlineCode",{parentName:"p"},"timeout: 30m"),"), ",(0,l.kt)("inlineCode",{parentName:"p"},"optional: true"),", or ",(0,l.kt)("inlineCode",{parentName:"p"},"negative: true")," for expecting failure."),(0,l.kt)("h3",{id:"matrix-and-sharding"},"Matrix and sharding"),(0,l.kt)("p",null,"The parallel steps are meant to support matrix and sharding, to run multiple replicas and/or distribute the load across multiple instances.\nIt is supported by regular matrix/sharding properties (",(0,l.kt)("inlineCode",{parentName:"p"},"matrix"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"shards"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"count")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"maxCount"),")."),(0,l.kt)("p",null,"You can read more about it in the general ",(0,l.kt)("a",{parentName:"p",href:"/articles/test-workflows-matrix-and-sharding"},(0,l.kt)("strong",{parentName:"a"},"Matrix and Sharding"))," documentation."),(0,l.kt)("h2",{id:"providing-content"},"Providing content"),(0,l.kt)("p",null,"There are multiple ways to provide the files for the parallel steps."),(0,l.kt)("admonition",{type:"info"},(0,l.kt)("p",{parentName:"admonition"},"As the parallel steps are started in separate pods, they don't share the file system with the Test Workflow execution.")),(0,l.kt)("h3",{id:"copying-content-inside"},"Copying content inside"),(0,l.kt)("p",null,"It is possible to copy the files from the original Test Workflow into the parallel steps.\nAs an example, you may want to fetch the repository and install the dependencies on the original TestWorkflow,\nand then distribute it across the parallel steps."),(0,l.kt)("p",null,"To do so, you can use ",(0,l.kt)("inlineCode",{parentName:"p"},"transfer")," property. It takes list of files to transfer:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},'{ from: "/data/repo/build" }')," will copy the ",(0,l.kt)("inlineCode",{parentName:"li"},"/data/repo/build")," directory from execution's Pod into ",(0,l.kt)("inlineCode",{parentName:"li"},"/data/repo/build")," in the instance's Pod"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},'{ from: "/data/repo/build", to: "/out" }')," will copy the ",(0,l.kt)("inlineCode",{parentName:"li"},"/data/repo/build")," directory from execution's Pod into ",(0,l.kt)("inlineCode",{parentName:"li"},"/out")," in the instance's Pod"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},'{ from: "/data/repo/build", to: "/out", "files": ["**/*.json"] }')," will copy only JSON files from the ",(0,l.kt)("inlineCode",{parentName:"li"},"/data/repo/build")," directory from execution's Pod into ",(0,l.kt)("inlineCode",{parentName:"li"},"/out")," in the instance's Pod")),(0,l.kt)("h4",{id:"example"},"Example"),(0,l.kt)("p",null,"The example below will:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Clone the Git repository (",(0,l.kt)("inlineCode",{parentName:"li"},"content"),")"),(0,l.kt)("li",{parentName:"ul"},"Install the Node.js dependencies (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].shell"),")"),(0,l.kt)("li",{parentName:"ul"},"Run Playwright tests (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel"),")",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Specify 2 instances of that step (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.count"),")"),(0,l.kt)("li",{parentName:"ul"},"Copy the ",(0,l.kt)("inlineCode",{parentName:"li"},"/data/repo")," along with already installed ",(0,l.kt)("inlineCode",{parentName:"li"},"node_modules")," (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.transfer"),")"),(0,l.kt)("li",{parentName:"ul"},"Run the Playwright test with customized ",(0,l.kt)("inlineCode",{parentName:"li"},"--shard")," parameter for each instance (",(0,l.kt)("inlineCode",{parentName:"li"},"1/2")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"2/2")," respectively, via ",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.shell"),")")))),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"yaml",label:"YAML",default:!0,mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: testworkflows.testkube.io/v1\nkind: TestWorkflow\nmetadata:\n  name: example-sharded-playwright-test\nspec:\n  content:\n    git:\n      uri: https://github.com/kubeshop/testkube\n      paths:\n      - test/playwright/executor-tests/playwright-project\n  container:\n    image: mcr.microsoft.com/playwright:v1.32.3-focal\n    workingDir: /data/repo/test/playwright/executor-tests/playwright-project\n\n  steps:\n  - name: Install dependencies\n    shell: 'npm ci'\n\n  - name: Run tests\n    parallel:\n      count: 2\n      transfer:\n      - from: /data/repo\n      shell: 'npx playwright test --shard {{ index + 1 }}/{{ count }}'\n"))),(0,l.kt)(i.Z,{value:"ui",label:"Log Output",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-sharded-playwright-test.png",src:a(14046).Z,width:"2158",height:"1956"})))),(0,l.kt)("h3",{id:"static-content-or-a-git-repository"},"Static content or a Git repository"),(0,l.kt)("admonition",{type:"tip"},(0,l.kt)("p",{parentName:"admonition"},"For distributed testing, it's better to avoid cloning repository in each step.\nInstead, that could be run on sequential step, and then transferred to parallel steps with ",(0,l.kt)("a",{parentName:"p",href:"#copying-content-inside"},(0,l.kt)("inlineCode",{parentName:"a"},"transfer")),"."),(0,l.kt)("p",{parentName:"admonition"},"This way you will spare the resources, as the computation and transferring over internet will happen only once. ")),(0,l.kt)("p",null,"Parallel steps allow to provide the ",(0,l.kt)("inlineCode",{parentName:"p"},"content")," property similar to the one directly in the Test Workflow. As an example, you may clone the repository:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: testworkflows.testkube.io/v1\nkind: TestWorkflow\nmetadata:\n  name: example-parallel-with-static-files\nspec:\n  steps:\n  - parallel:\n      count: 2\n      content:\n        files:\n        - path: /k6.js\n          content: |\n            import http from 'k6/http';\n            export const options = {\n              thresholds: {\n                http_req_failed: ['rate<0.01'],\n              }\n            };\n            export default function () {\n              http.get('https://testkube.io/');\n            }\n      run:\n        image: grafana/k6:latest\n        shell: \"k6 run /k6.js --iterations 100\"\n")),(0,l.kt)("h2",{id:"synchronising-the-parallel-steps-execution"},"Synchronising the parallel steps execution"),(0,l.kt)("p",null,"By default, each parallel step is executed as soon as it is possible. There is an option to override it though, so they won't start until all the instances are ready.\nThe pods may start at different time, especially with ",(0,l.kt)("a",{parentName:"p",href:"https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-provisioning"},"node auto-provisioning"),"."),(0,l.kt)("p",null,"It's especially useful for load testing, like K6, as you want to have the distributed load test executed at the same time."),(0,l.kt)("p",null,"To achieve that with parallel steps, simply add ",(0,l.kt)("inlineCode",{parentName:"p"},"paused: true")," clause directly under the parallel, or to the specific step that it should stay at.\nThis way, the tests won't get started, until all steps have reached that point."),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"yaml",label:"YAML",default:!0,mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: testworkflows.testkube.io/v1\nkind: TestWorkflow\nmetadata:\n  name: example-parallel-with-static-files\nspec:\n  steps:\n  - parallel:\n      count: 2\n      paused: true\n      content:\n        files:\n        - path: /k6.js\n          content: |\n            import http from 'k6/http';\n            export const options = {\n              thresholds: {\n                http_req_failed: ['rate<0.01'],\n              }\n            };\n            export default function () {\n              http.get('https://testkube.io/');\n            }\n      run:\n        image: grafana/k6:latest\n        shell: \"k6 run /k6.js --iterations 100\"\n"))),(0,l.kt)(i.Z,{value:"log",label:"Log Output",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-workflow-sync-lock.png",src:a(94236).Z,width:"2150",height:"1688"})))),(0,l.kt)("h2",{id:"reading-files-from-parallel-steps"},"Reading files from parallel steps"),(0,l.kt)("p",null,"In the opposite to copying the files into the parallel steps pod, you may want to read reports or other data ",(0,l.kt)("strong",{parentName:"p"},"from")," them too.\nThere are 2 basic methods to achieve that."),(0,l.kt)("h3",{id:"artifacts"},"Artifacts"),(0,l.kt)("p",null,"The parallel steps may expose data as artifacts, just the same way as sequential step. The artifacts from different steps will be isolated."),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"yaml",label:"YAML",default:!0,mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: testworkflows.testkube.io/v1\nkind: TestWorkflow\nmetadata:\n  name: example-sharded-playwright-test-with-artifacts\nspec:\n  content:\n    git:\n      uri: https://github.com/kubeshop/testkube\n      paths:\n      - test/playwright/executor-tests/playwright-project\n  container:\n    image: mcr.microsoft.com/playwright:v1.32.3-focal\n    workingDir: /data/repo/test/playwright/executor-tests/playwright-project\n\n  steps:\n  - name: Install dependencies\n    shell: 'npm ci'\n\n  - name: Run tests\n    parallel:\n      count: 2\n      transfer:\n      - from: /data/repo\n      container:\n        env:\n        - name: PLAYWRIGHT_HTML_REPORT\n          value: /data/out/playwright-report\n      shell: 'npx playwright test --output /data/out --shard {{ index + 1 }}/{{ count }}'\n      artifacts:\n        workingDir: /data/out\n        paths:\n        - '**/*'\n"))),(0,l.kt)(i.Z,{value:"log",label:"Log Output",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-sharded-playwright-test-with-artifacts-logs.png",src:a(93323).Z,width:"2156",height:"2026"}))),(0,l.kt)(i.Z,{value:"artifacts",label:"Artifacts",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-sharded-playwright-test-with-artifacts-artifacts.png",src:a(41994).Z,width:"2160",height:"2030"})))),(0,l.kt)("h3",{id:"fetching-files-back-to-executions-pod"},"Fetching files back to execution's Pod"),(0,l.kt)("p",null,"Alternatively, you can use ",(0,l.kt)("inlineCode",{parentName:"p"},"fetch")," instruction. ",(0,l.kt)("inlineCode",{parentName:"p"},"fetch")," syntax is similar to ",(0,l.kt)("inlineCode",{parentName:"p"},"transfer"),", but instead of copying data from execution's Pod into parallel instance's Pod,\nit's copying the other way - from parallel instance's Pod back to execution's."),(0,l.kt)("p",null,"Afterward, you can process these files, or i.e. build not isolated artifacts."),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"yaml",label:"YAML",default:!0,mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: testworkflows.testkube.io/v1\nkind: TestWorkflow\nmetadata:\n  name: example-sharded-playwright-test-with-artifacts-fetch\nspec:\n  content:\n    git:\n      uri: https://github.com/kubeshop/testkube\n      paths:\n      - test/playwright/executor-tests/playwright-project\n  container:\n    image: mcr.microsoft.com/playwright:v1.32.3-focal\n    workingDir: /data/repo/test/playwright/executor-tests/playwright-project\n\n  steps:\n  - name: Install dependencies\n    shell: 'npm ci'\n\n  - name: Run tests\n    parallel:\n      count: 2\n      transfer:\n      - from: /data/repo\n      fetch:\n      - from: /data/out\n        to: /data/artifacts/instance-{{ index }}\n      container:\n        env:\n        - name: PLAYWRIGHT_HTML_REPORT\n          value: /data/out/playwright-report\n      shell: 'npx playwright test --output /data/out --shard {{ index + 1 }}/{{ count }}'\n\n  - condition: always\n    artifacts:\n      workingDir: /data/artifacts\n      paths:\n      - '**/*'\n"))),(0,l.kt)(i.Z,{value:"log",label:"Log Output",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-sharded-playwright-test-with-artifacts-fetch-logs.png",src:a(54694).Z,width:"2160",height:"2024"}))),(0,l.kt)(i.Z,{value:"artifacts",label:"Artifacts",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-sharded-playwright-test-with-artifacts-fetch-artifacts.png",src:a(9481).Z,width:"2158",height:"2032"})))),(0,l.kt)("h2",{id:"examples"},"Examples"),(0,l.kt)("h3",{id:"sharded-playwright-with-single-report"},"Sharded Playwright with single report"),(0,l.kt)("admonition",{type:"info"},(0,l.kt)("p",{parentName:"admonition"},"Blob reporter and merging reports have landed in Playwright 1.37.0, so it's not available before.")),(0,l.kt)("p",null,"Playwright provides nice toolset for sharding, which can be used easily with the Test Workflows."),(0,l.kt)("p",null,"The example below:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Load the Git repository with Playwright test (",(0,l.kt)("inlineCode",{parentName:"li"},"content"),")"),(0,l.kt)("li",{parentName:"ul"},"Install the project dependencies (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].shell"),")"),(0,l.kt)("li",{parentName:"ul"},"Run the Playwright tests split to 2 shards (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel"),")",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Reserve 1 CPU and 1GB RAM for each shard (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.container.resources"),")"),(0,l.kt)("li",{parentName:"ul"},"Copy the repository and ",(0,l.kt)("inlineCode",{parentName:"li"},"node_modules")," inside (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.transfer"),")"),(0,l.kt)("li",{parentName:"ul"},"Run Playwright test - with ",(0,l.kt)("inlineCode",{parentName:"li"},"blob")," reporter, and with specific shard segment (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.shell"),")"),(0,l.kt)("li",{parentName:"ul"},"Fetch the Blob reporter's data to corresponding directory on Execution's pod (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.fetch"),")"))),(0,l.kt)("li",{parentName:"ul"},"Merge the reports using Playwright's tooling (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[2].shell"),")"),(0,l.kt)("li",{parentName:"ul"},"Save the merged report as an artifact (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[2].artifacts"),")")),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"yaml",label:"YAML",default:!0,mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: testworkflows.testkube.io/v1\nkind: TestWorkflow\nmetadata:\n  name: example-sharded-playwright-with-merged-report\nspec:\n  content:\n    git:\n      uri: https://github.com/kubeshop/testkube\n      paths:\n      - test/playwright/executor-tests/playwright-project\n  container:\n    image: mcr.microsoft.com/playwright:v1.38.0-focal\n    workingDir: /data/repo/test/playwright/executor-tests/playwright-project\n\n  steps:\n  - name: Install dependencies\n    shell: 'npm install --save-dev @playwright/test@1.38.0 && npm ci'\n\n  - name: Run tests\n    parallel:\n      count: 2\n      transfer:\n      - from: /data/repo\n      fetch:\n      - from: /data/repo/test/playwright/executor-tests/playwright-project/blob-report\n        to: /data/reports\n      container:\n        resources:\n          requests:\n            cpu: 1\n            memory: 1Gi\n      shell: |\n        npx playwright test --reporter blob --shard {{ index + 1 }}/{{ count }}\n\n  - name: Merge reports\n    condition: always\n    shell: 'npx playwright merge-reports --reporter=html /data/reports'\n    artifacts:\n      paths:\n      - 'playwright-report/**'\n"))),(0,l.kt)(i.Z,{value:"log",label:"Log Output",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-sharded-playwright-with-merged-report-logs.png",src:a(56394).Z,width:"2160",height:"2144"}))),(0,l.kt)(i.Z,{value:"artifacts",label:"Artifacts",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-sharded-playwright-with-merged-report-artifacts.png",src:a(70129).Z,width:"2158",height:"2130"})))),(0,l.kt)("h3",{id:"automatically-sharded-cypress-tests"},"Automatically sharded Cypress tests"),(0,l.kt)("p",null,"Cypress doesn't have any built-in way for sharding, but Test Workflow's ",(0,l.kt)("a",{parentName:"p",href:"/articles/test-workflows-matrix-and-sharding"},(0,l.kt)("strong",{parentName:"a"},"matrix and sharding")),"\nworks well with all kinds of tests."),(0,l.kt)("p",null,"While the example here is not a perfect solution, it's sharding the Cypress tests based on the available test files."),(0,l.kt)("p",null,"The example below:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Load the Cypress tests from the Git repository (",(0,l.kt)("inlineCode",{parentName:"li"},"content"),")"),(0,l.kt)("li",{parentName:"ul"},"Sets the working directory to the tests one (",(0,l.kt)("inlineCode",{parentName:"li"},"container.workingDir"),")"),(0,l.kt)("li",{parentName:"ul"},"Install the project dependencies (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].shell"),")"),(0,l.kt)("li",{parentName:"ul"},"Run Cypress tests with dynamic sharding (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel"),")",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"The shards will be built off the test files in ",(0,l.kt)("inlineCode",{parentName:"li"},"cypress/e2e")," directory (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.shards.testFiles"),")"),(0,l.kt)("li",{parentName:"ul"},"It will have maximum of 5 shards (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.maxCount"),")",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"When there is less than or equal to 5 test files, it will run 1 shard per test file"),(0,l.kt)("li",{parentName:"ul"},"When there will be more than 5 test files, it will distribute them across 5 shards"))),(0,l.kt)("li",{parentName:"ul"},"Each shard will run only selected test files with ",(0,l.kt)("inlineCode",{parentName:"li"},"--spec")," Cypress' argument (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[1].parallel.run.args"),")")))),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"yaml",label:"YAML",default:!0,mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: testworkflows.testkube.io/v1\nkind: TestWorkflow\nmetadata:\n  name: example-sharded-cypress\nspec:\n  content:\n    git:\n      uri: https://github.com/kubeshop/testkube\n      paths:\n      - test/cypress/executor-tests/cypress-13\n  container:\n    image: cypress/included:13.6.4\n    workingDir: /data/repo/test/cypress/executor-tests/cypress-13\n\n  steps:\n  - name: Install dependencies\n    shell: \'npm ci\'\n\n  - name: Run tests\n    parallel:\n      maxCount: 5\n      shards:\n        testFiles: \'glob("cypress/e2e/**/*.js")\'\n      description: \'{{ join(map(shard.testFiles, "relpath(_.value, \\"cypress/e2e\\")"), ", ") }}\'\n      transfer:\n      - from: /data/repo\n      container:\n        resources:\n          requests:\n            cpu: 1\n            memory: 1Gi\n        env:\n        - name: CYPRESS_CUSTOM_ENV\n          value: CYPRESS_CUSTOM_ENV_value\n      run:\n        args:\n        - --env\n        - NON_CYPRESS_ENV=NON_CYPRESS_ENV_value\n        - --spec\n        - \'{{ join(shard.testFiles, ",") }}\'\n'))),(0,l.kt)(i.Z,{value:"log",label:"Log Output",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-sharded-cypress.png",src:a(48368).Z,width:"2158",height:"1952"})))),(0,l.kt)("h3",{id:"distributed-k6-load-testing"},"Distributed K6 load testing"),(0,l.kt)("admonition",{type:"tip"},(0,l.kt)("p",{parentName:"admonition"},"If you have multiple suites, you may consider exposing such executor as a Test Workflow Template,\nand declare contents by ",(0,l.kt)("inlineCode",{parentName:"p"},"config")," parameters. Alternatively, you can use ",(0,l.kt)("inlineCode",{parentName:"p"},"config")," directly in Test Workflow.")),(0,l.kt)("p",null,"You can simply run K6 load tests distributed across all your nodes. The mechanism is similar to what ",(0,l.kt)("a",{parentName:"p",href:"https://grafana.com/docs/k6/latest/testing-guides/running-distributed-tests/"},(0,l.kt)("strong",{parentName:"a"},"k6-operator"))," has under the hood,\nbut it's much more powerful and flexible."),(0,l.kt)("p",null,"The example below:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Takes optional run configuration parameters (",(0,l.kt)("inlineCode",{parentName:"li"},"config"),")",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"vus")," to declare Virtual Users to distribute"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"duration")," to declare Load Test time"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"workers")," to declare number of K6 instances to create"))),(0,l.kt)("li",{parentName:"ul"},"Load the K6 script from Git repository (",(0,l.kt)("inlineCode",{parentName:"li"},"content"),")"),(0,l.kt)("li",{parentName:"ul"},"Run distributed K6 tests (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].parallel"),")",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"It's using built-in ",(0,l.kt)("inlineCode",{parentName:"li"},"distribute/evenly")," Test Workflow Template, that sets ",(0,l.kt)("a",{parentName:"li",href:"https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/"},(0,l.kt)("inlineCode",{parentName:"a"},"pod.topologySpreadConstraints"))," to distribute pods evenly across nodes (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].parallel.use"),")"),(0,l.kt)("li",{parentName:"ul"},"It's creating as many K6 workers as has been declared in ",(0,l.kt)("inlineCode",{parentName:"li"},"workers")," config (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].parallel.count"),")"),(0,l.kt)("li",{parentName:"ul"},"It copies the test case from Git repository into workers (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].parallel.transfer"),")"),(0,l.kt)("li",{parentName:"ul"},"It reserves 1/8 CPU and 128MB for each worker (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].parallel.container.resources"),")"),(0,l.kt)("li",{parentName:"ul"},"It ensures that all workers will start load tests at the same time, when all are ready (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].parallel.paused"),")"),(0,l.kt)("li",{parentName:"ul"},"It runs K6 executable against that test case (",(0,l.kt)("inlineCode",{parentName:"li"},"steps[0].parallel.run.shell"),")",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"It passes number of Virtual Users and test duration via K6 parameters"),(0,l.kt)("li",{parentName:"ul"},"It uses K6 ",(0,l.kt)("a",{parentName:"li",href:"https://grafana.com/docs/k6/latest/using-k6/k6-options/reference/#execution-segment"},(0,l.kt)("strong",{parentName:"a"},"--execution-segment"))," argument to select the fraction of tests to run")))))),(0,l.kt)(r.Z,{mdxType:"Tabs"},(0,l.kt)(i.Z,{value:"yaml",label:"YAML",default:!0,mdxType:"TabItem"},(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: testworkflows.testkube.io/v1\nkind: TestWorkflow\nmetadata:\n  name: example-distributed-k6\n  labels:\n    core-tests: workflows\nspec:\n  config:\n    vus: {type: integer, default: 100}\n    duration: {type: string, default: '5s'}\n    workers: {type: integer, default: 10}\n  content:\n    git:\n      uri: https://github.com/kubeshop/testkube\n      paths:\n      - test/k6/executor-tests/k6-smoke-test.js\n\n  steps:\n  - name: Run test\n    parallel:\n      count: 'config.workers'\n      transfer:\n      - from: /data/repo\n      use:\n      - name: distribute/evenly\n      container:\n        workingDir: /data/repo/test/k6/executor-tests\n        resources:\n          requests:\n            cpu: 128m\n            memory: 128Mi\n        env:\n        - name: K6_SYSTEM_ENV\n          value: K6_SYSTEM_ENV_value\n      paused: true\n      run:\n        image: grafana/k6:0.49.0\n        shell: |\n          k6 run k6-smoke-test.js \\\n            -e K6_ENV_FROM_PARAM=K6_ENV_FROM_PARAM_value \\\n            --vus {{ config.vus }} \\\n            --duration {{ shellquote(config.duration) }} \\\n            --execution-segment {{ index }}/{{ count }}:{{ index + 1 }}/{{ count }}\n"))),(0,l.kt)(i.Z,{value:"run",label:"Run Options",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-distributed-k6-run.png",src:a(95428).Z,width:"4110",height:"2388"}))),(0,l.kt)(i.Z,{value:"log",label:"Log Output",mdxType:"TabItem"},(0,l.kt)("p",null,(0,l.kt)("img",{alt:"example-distributed-k6-logs.png",src:a(391).Z,width:"1918",height:"2396"})))))}m.isMDXComponent=!0},391:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-distributed-k6-logs-bae5371415609c5aeabdbe672a605a04.png"},95428:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-distributed-k6-run-1ff80622eef25d396546420c05823fd8.png"},87742:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-parallel-log-c1aed962368d6123b554e56c182b9a04.png"},48368:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-sharded-cypress-99bd277f312748c079ae253e3e98eb24.png"},41994:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-sharded-playwright-test-with-artifacts-artifacts-be157dd66bc52edea887676c2ddcf2a5.png"},9481:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-sharded-playwright-test-with-artifacts-fetch-artifacts-66b67cda8ff3e7ec08876c06361f28ee.png"},54694:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-sharded-playwright-test-with-artifacts-fetch-logs-2c0c0c2e9485a8b0c932555238ec7e8a.png"},93323:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-sharded-playwright-test-with-artifacts-logs-31e20dae8a9fb69e22b1717df42a296c.png"},14046:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-sharded-playwright-test-705e0c2ff266708707255efd3992412d.png"},70129:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-sharded-playwright-with-merged-report-artifacts-a5ba4cead9fa99cb4f0e392c298c4afa.png"},56394:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-sharded-playwright-with-merged-report-logs-cc48b2994cc52b0edfaebac2853240ea.png"},94236:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/example-workflow-sync-lock-3c77ca2d3bd9efdb76b939dc65dc1135.png"}}]);